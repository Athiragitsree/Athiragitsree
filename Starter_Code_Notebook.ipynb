{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANJALI RANA\n",
    "### Std. ID: 216752057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VORJ7b-AY4jZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       48842 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      48842 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48842 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "None\n",
      "\n",
      "Target Variable Distribution:\n",
      "income\n",
      "<=50K     24720\n",
      "<=50K.    12435\n",
      ">50K       7841\n",
      ">50K.      3846\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7890 - loss: 2.4026 - val_accuracy: 0.8119 - val_loss: 2.7090\n",
      "Epoch 2/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.8117 - loss: 2.5598 - val_accuracy: 0.8411 - val_loss: 2.0923\n",
      "Epoch 3/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.8254 - loss: 2.4833 - val_accuracy: 0.8333 - val_loss: 2.4137\n",
      "Epoch 4/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.8258 - loss: 2.4887 - val_accuracy: 0.8328 - val_loss: 2.2910\n",
      "Epoch 5/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.8134 - loss: 2.5977 - val_accuracy: 0.8344 - val_loss: 2.4961\n",
      "Epoch 6/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.8357 - loss: 2.4772 - val_accuracy: 0.8450 - val_loss: 2.2766\n",
      "Epoch 7/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.8351 - loss: 2.4266 - val_accuracy: 0.8261 - val_loss: 2.5804\n",
      "Epoch 8/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.8345 - loss: 2.4631 - val_accuracy: 0.8445 - val_loss: 2.3366\n",
      "Epoch 9/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.8461 - loss: 2.3180 - val_accuracy: 0.8445 - val_loss: 2.2793\n",
      "Epoch 10/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.8393 - loss: 2.3532 - val_accuracy: 0.8500 - val_loss: 2.2255\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      7414\n",
      "           1       0.73      0.53      0.61      2355\n",
      "\n",
      "    accuracy                           0.84      9769\n",
      "   macro avg       0.80      0.73      0.76      9769\n",
      "weighted avg       0.83      0.84      0.83      9769\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6951  463]\n",
      " [1110 1245]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Replace 'path_to_data' with the actual path to the data files\n",
    "# adult_data = pd.read_csv(\"adult.data\", header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
    "# adult_test = pd.read_csv(\"adult.test\", header=1, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
    "\n",
    "# train_data_path = 'path_to_data/adult.data'\n",
    "# test_data_path = 'path_to_data/adult.test'\n",
    "\n",
    "# Define column names based on dataset structure\n",
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
    "    \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# Load train and test datasets\n",
    "train_data = pd.read_csv(\"adult.data\", header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
    "test_data = pd.read_csv(\"adult.test\", header=None, names=columns, skiprows=1, na_values=\" ?\", skipinitialspace=True)\n",
    "\n",
    "# Combine train and test data for preprocessing\n",
    "data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "# Step 2: Explore the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nTarget Variable Distribution:\")\n",
    "print(data['income'].value_counts())\n",
    "\n",
    "# Step 3: Handle missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Step 4: Separate features and target\n",
    "X = data.drop(columns=[\"income\"])\n",
    "y = data[\"income\"].apply(lambda x: 1 if \">50K\" in x else 0)  # Encode target as binary\n",
    "\n",
    "# Step 5: Define preprocessing pipeline\n",
    "categorical_columns = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_columns = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_columns),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Deep Learning Model (Starter Code)\n",
    "# Uncomment the following block to start building your model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=input_dim),  # Choose appropriate activation function\n",
    "        Dropout(0.3), # Feel free to remove the Dropout layers if they are not needed\n",
    "        Dense(64),  # Choose appropriate activation function\n",
    "        Dropout(0.3),\n",
    "        Dense(1),  # Choose appropriate activation function for binary classification\n",
    "    ])\n",
    "    # Compile the model with an optimizer and loss function\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and train the model\n",
    "model = build_model(X_train.shape[1])\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=32)\n",
    "\n",
    "# Step 8: Model Evaluation\n",
    "# Uncomment this block to evaluate your model\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step\n",
      "\n",
      "Metrics for predicting income '>50K':\n",
      "Precision: 0.73\n",
      "Recall: 0.53\n",
      "F1-Score: 0.61\n",
      "Support: 2355.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict the outcomes on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)  # Convert report to a dictionary for easy access\n",
    "\n",
    "# Extract the metrics specifically for \">50K\" (class 1)\n",
    "class_1_metrics = report['1']  # Metrics for class 1 (\">50K\")\n",
    "\n",
    "# Print the metrics for class \">50K\"\n",
    "print(\"\\nMetrics for predicting income '>50K':\")\n",
    "print(f\"Precision: {class_1_metrics['precision']:.2f}\")\n",
    "print(f\"Recall: {class_1_metrics['recall']:.2f}\")\n",
    "print(f\"F1-Score: {class_1_metrics['f1-score']:.2f}\")\n",
    "print(f\"Support: {class_1_metrics['support']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for CNN\n",
    "X_train_reshaped = X_train.toarray().reshape(X_train.shape[0], X_train.shape[1], 1)  # Convert sparse to dense if necessary\n",
    "X_test_reshaped = X_test.toarray().reshape(X_test.shape[0], X_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        Flatten(),  # Flatten the 1D output into a vector\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification output\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.3907 - val_accuracy: 0.8480 - val_loss: 0.3333\n",
      "Epoch 2/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.3476 - val_accuracy: 0.8527 - val_loss: 0.3220\n",
      "Epoch 3/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3320 - val_accuracy: 0.8560 - val_loss: 0.3173\n",
      "Epoch 4/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8427 - loss: 0.3349 - val_accuracy: 0.8550 - val_loss: 0.3164\n",
      "Epoch 5/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.3283 - val_accuracy: 0.8575 - val_loss: 0.3140\n",
      "Epoch 6/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.3242 - val_accuracy: 0.8545 - val_loss: 0.3164\n",
      "Epoch 7/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8519 - loss: 0.3241 - val_accuracy: 0.8590 - val_loss: 0.3108\n",
      "Epoch 8/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 0.3210 - val_accuracy: 0.8562 - val_loss: 0.3117\n",
      "Epoch 9/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3157 - val_accuracy: 0.8582 - val_loss: 0.3116\n",
      "Epoch 10/10\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 0.3224 - val_accuracy: 0.8571 - val_loss: 0.3119\n"
     ]
    }
   ],
   "source": [
    "# Reshape data for CNN\n",
    "X_train_reshaped = X_train.toarray().reshape(X_train.shape[0], X_train.shape[1], 1)  # Add channel dimension\n",
    "X_test_reshaped = X_test.toarray().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = build_cnn_model((X_train_reshaped.shape[1], 1))  # Input shape: (features, 1 channel)\n",
    "\n",
    "# Train the CNN model\n",
    "history = cnn_model.fit(\n",
    "    X_train_reshaped, y_train, \n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    epochs=10,            # Number of training epochs\n",
    "    batch_size=32,        # Batch size\n",
    "    verbose=1             # Print training progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model is generalizing the problem well as we see the training accuracy (85.10%) is very close to the validation accuracy (85.71%) by the 10th epoch and both training and validation accuracy stays close throughout all 1-10th epoch, making it that model is generalize. Similarly, the training loss (0.3224) and validation loss (0.3119) are also nearly identical which shows that the model performs consistently on both the training and validation data. Hence indicating  that the model is neither overfitting nor underfitting but is generalizing the problem.\n",
    "\n",
    "- Now as you may see in the jupyterfile, the training accuracy steadily improves from 81.90% in the first epoch to 85.10% by the 10th epoch, which tells that the model is learning effectively. Same with the validation accuracy which starts improving early and stabilizes between 85.6% and 85.9% in the later epochs.\n",
    "\n",
    "- Now this close match between training and validation performance suggests that the model is balanced and overall generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.3158 - val_accuracy: 0.8612 - val_loss: 0.3119\n",
      "Epoch 2/20\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.3227 - val_accuracy: 0.8596 - val_loss: 0.3097\n",
      "Epoch 3/20\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8568 - loss: 0.3126 - val_accuracy: 0.8587 - val_loss: 0.3094\n",
      "Epoch 4/20\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3203 - val_accuracy: 0.8581 - val_loss: 0.3088\n",
      "Epoch 5/20\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3204 - val_accuracy: 0.8582 - val_loss: 0.3088\n",
      "Epoch 6/20\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3171 - val_accuracy: 0.8557 - val_loss: 0.3122\n",
      "Epoch 7/20\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8601 - loss: 0.3093 - val_accuracy: 0.8594 - val_loss: 0.3126\n",
      "Epoch 8/20\n",
      "\u001b[1m977/977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.3153 - val_accuracy: 0.8583 - val_loss: 0.3091\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "# history = cnn_model.fit(X_train_reshaped, y_train, validation_split=0.2, epochs=20, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN\n",
    "#cnn_model = build_cnn_model((X_train_reshaped.shape[1], 1))  # Shape: (features, 1 channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.8462 - loss: 0.3217\n",
      "Test Loss: 0.3193, Test Accuracy: 0.8502\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      7414\n",
      "           1       0.77      0.54      0.64      2355\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.82      0.75      0.77      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test_reshaped, y_test)\n",
    "print(f\"Test Loss: {cnn_loss:.4f}, Test Accuracy: {cnn_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "y_pred_cnn = (cnn_model.predict(X_test_reshaped) > 0.5).astype(int)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_cnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step\n",
      "\n",
      "Top 3 Features Contributing to Income Prediction (CNN):\n",
      "1. num__capital-gain: 0.0304\n",
      "2. num__education-num: 0.0120\n",
      "3. cat__relationship_Not-in-family: 0.0106\n"
     ]
    }
   ],
   "source": [
    "#Feature selection\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a function to evaluate the CNN model accuracy\n",
    "def cnn_model_score(X, y):\n",
    "    y_pred = (cnn_model.predict(X) > 0.5).astype(int)\n",
    "    return accuracy_score(y, y_pred)\n",
    "\n",
    "# Calculate baseline accuracy for the CNN model\n",
    "cnn_baseline_score = cnn_model_score(X_test_reshaped, y_test)\n",
    "\n",
    "# Calculate permutation importance for CNN\n",
    "cnn_importance = []\n",
    "for col in range(X_test_dense.shape[1]):\n",
    "    X_test_shuffled = X_test_dense.copy()\n",
    "    np.random.shuffle(X_test_shuffled[:, col])  # Shuffle one column at a time\n",
    "    \n",
    "    # Reshape back to CNN input format\n",
    "    X_test_shuffled_reshaped = X_test_shuffled.reshape(X_test_shuffled.shape[0], X_test_shuffled.shape[1], 1)\n",
    "    \n",
    "    # Evaluate accuracy with shuffled feature\n",
    "    shuffled_score = cnn_model_score(X_test_shuffled_reshaped, y_test)\n",
    "    cnn_importance.append(cnn_baseline_score - shuffled_score)\n",
    "\n",
    "# Map feature indices to feature names\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "cnn_feature_importances = list(zip(feature_names, cnn_importance))\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_cnn_features = sorted(cnn_feature_importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top 3 features\n",
    "print(\"\\nTop 3 Features Contributing to Income Prediction (CNN):\")\n",
    "for i, (feature, imp) in enumerate(sorted_cnn_features[:3], 1):\n",
    "    print(f\"{i}. {feature}: {imp:.4f}\")\n",
    "\n",
    "# Optionally, display all feature importances\n",
    "# for feature, imp in sorted_cnn_features:\n",
    "#     print(f\"{feature}: {imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7015  399]\n",
      " [1049 1306]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "# Generate predictions\n",
    "y_pred_cnn = (cnn_model.predict(X_test_reshaped) > 0.5).astype(int)  # Binary predictions\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_cnn)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"<=50K\", \">50K\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "disp.ax_.set_title(\"Confusion Matrix for CNN Model\")\n",
    "disp.ax_.set_xlabel(\"Predicted Label\")\n",
    "disp.ax_.set_ylabel(\"True Label\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_cnn))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numerical Values from the Confusion Matrix\n",
    "    - True Negatives (TN): 7015 - The model correctly predicted \"<=50K\" for 7015 individuals.\n",
    "    - False Positives (FP): 399- The model incorrectly predicted \">50K\" for 399 individuals who actually earn \"<=50K\".\n",
    "    - False Negatives (FN): 1049 - The model incorrectly predicted \"<=50K\" for 1049 individuals who actually earn \">50K\".\n",
    "    - True Positives (TP): 1306 - The model correctly predicted \">50K\" for 1306 individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step\n",
      "False Negative Rate (FNR) for '>50K': 0.45\n",
      "False Positive Rate (FPR) for '>50K': 0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_cnn = (cnn_model.predict(X_test_reshaped) > 0.5).astype(int)\n",
    "\n",
    "# Get confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_cnn).ravel()\n",
    "\n",
    "# Calculate FNR and FPR\n",
    "fnr = fn / (fn + tp)  # False Negative Rate\n",
    "fpr = fp / (fp + tn)  # False Positive Rate\n",
    "\n",
    "print(f\"False Negative Rate (FNR) for '>50K': {fnr:.2f}\")\n",
    "print(f\"False Positive Rate (FPR) for '>50K': {fpr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step\n",
      "\n",
      "Classification Report with Threshold 0.7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90      7414\n",
      "           1       0.87      0.35      0.50      2355\n",
      "\n",
      "    accuracy                           0.83      9769\n",
      "   macro avg       0.85      0.67      0.70      9769\n",
      "weighted avg       0.84      0.83      0.80      9769\n",
      "\n",
      "\n",
      "Confusion Matrix with Threshold 0.7:\n",
      "[[7295  119]\n",
      " [1529  826]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Adjust the decision threshold from 0.5 to 0.7\n",
    "threshold = 0.7\n",
    "y_pred_adjusted = (cnn_model.predict(X_test_reshaped) > threshold).astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "adjusted_report = classification_report(y_test, y_pred_adjusted)\n",
    "print(\"\\nClassification Report with Threshold 0.7:\")\n",
    "print(adjusted_report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_adjusted = confusion_matrix(y_test, y_pred_adjusted)\n",
    "print(\"\\nConfusion Matrix with Threshold 0.7:\")\n",
    "print(cm_adjusted)\n",
    "\n",
    "# # Classification report\n",
    "# y_pred_cnn = (cnn_model.predict(X_test_reshaped) > 0.5).astype(int)\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred_cnn))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
